{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import importlib\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "from typing import Tuple, Callable, Any, NoReturn, List, Dict, Optional, Union\n",
    "\n",
    "from functools import partial, reduce\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pdf2image.exceptions import (\n",
    "    PDFInfoNotInstalledError,\n",
    "    PDFPageCountError,\n",
    "    PDFSyntaxError\n",
    ")\n",
    "\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timing\n",
    "importlib.reload(timing)\n",
    "import timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a multiprocess pool.\n",
    "pool = mp.Pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing.time_log()\n",
    "def images_to_strings(x) -> Dict[str, List[str]]:\n",
    "    \"\"\" Envoltura para generar un diccionario del tipo :\n",
    "            {\n",
    "                \"nombre del archivo PDF\": [Lista de strings, uno por página]\n",
    "            }\n",
    "        \n",
    "        A partir de un diccionario del tipo:\n",
    "            { \n",
    "                \"nombre del achivo PDF\": [Lista contendiendo una imagen por página]\n",
    "            }\n",
    "            \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        nombre: pool.map(pytesseract.image_to_string, archivo) for nombre, archivo in x.items()\n",
    "    }\n",
    "##\n",
    "\n",
    "@timing.time_log()\n",
    "def tab_by_regex(x: str) -> str:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    newline = lambda x: f\"{x}\\n\"\n",
    "    ntab    = lambda n, txt: n*\"\\t\" + txt\n",
    "    \n",
    "    _x_lines: List[str] = x.split('\\n')\n",
    "    _my_str:  str       = ''\n",
    "        \n",
    "    for line in _x_lines:\n",
    "        # Match lines starting with Caps, separated by spaces or points : \n",
    "        # r\"^([A-Z\\s|[A-Z]\\.?)+?(?=(\\..+))\" # found on a separate cell down\n",
    "        # r\"^([A-Z\\s]|[A-Z]\\.?)+?(?=(\\..+))\" # the legacy regex for this func\n",
    "        for i in regex.finditer(r\"^([A-Z\\s|[A-Z]\\.?)+?(?=(\\..+))\", line): \n",
    "            _my_str += newline(i.string)\n",
    "            _my_str += newline(ntab(1, i.group()))\n",
    "            # Match numbers, which could be either integers or floats : \n",
    "            for j in regex.finditer(r\"(\\d+\\.\\d+|\\d+)\", i.string): # find groups of numbers\n",
    "                _my_str += newline(ntab(2, j.group()))\n",
    "            # Match strings found between numbers :\n",
    "            for k in regex.finditer(r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\d]+?(?=\\s)\", i.string):\n",
    "                _my_str += newline(ntab(3, k.group()))\n",
    "    \n",
    "    return _my_str\n",
    "##\n",
    "\n",
    "@timing.time_log()\n",
    "def dict_from_regex(x: str) -> str:\n",
    "    \"\"\"\n",
    "        Genera un directorio con los valores deseado\n",
    "    \"\"\"\n",
    "    \n",
    "    _x_lines: List[str] = x.split('\\n')\n",
    "    \n",
    "    _dict2 = {}\n",
    "    for line in _x_lines:\n",
    "        for i in regex.finditer(r\"^([A-Z\\s|[A-Z]\\.?)+?(?=(\\..+))\", line): \n",
    "            i.group()\n",
    "            _valores = []\n",
    "            _unidades = []\n",
    "            # Match numbers, which could be either integers or floats : \n",
    "            for j in regex.finditer(r\"(\\d+\\.\\d+|\\d+)\", i.string):\n",
    "                _valores.append(float(j.group()))\n",
    "            # Match strings found between numbers :\n",
    "            for k in regex.finditer(r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\d]+?(?=\\s)\", i.string):\n",
    "                _unidades.append(k.group())\n",
    "            if len(_valores) < 5 and len(_unidades) < 5:\n",
    "                _dict2.update({\n",
    "                    i.group(): {\n",
    "                        \"values\": _valores,\n",
    "                        \"units\": _unidades\n",
    "                    }\n",
    "                })\n",
    "    \n",
    "    return _dict2\n",
    "##\n",
    "\n",
    "@timing.time_log()\n",
    "def save_results(x: Dict[str, List[str]]) -> bool:\n",
    "    \"\"\"\n",
    "        Guarda los strings a los cuales ya se les han aplicado los filtros.\n",
    "            \n",
    "        El modo de escritura es 'w', o sea 'write'.\n",
    "        Cada vez que se llame esta función los resultados anteriormente guardados \n",
    "        serán sobreescritos por los nuevos generados.\n",
    "        \n",
    "        La función crea un directorio llamado 'segmented' si es que \n",
    "        éste no existe.\n",
    "        \n",
    "        Después guarda todos los archivos en dicho directorio.\n",
    "        \n",
    "        Regresa:\n",
    "            'True',  si se logran generar los archivos.\n",
    "            \n",
    "            'False', si ocurre algún error.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if 'segmented' not in os.listdir('.'):\n",
    "            os.mkdir('segmented')\n",
    "        \n",
    "        _camino_resultados = os.path.abspath('segmented')\n",
    "        _archivos =  list(x.keys())\n",
    "    \n",
    "        for i, archivo in enumerate(_archivos):\n",
    "            for j, page in enumerate(x[archivo]):\n",
    "                with open(os.path.join(_camino_resultados, f\"{_archivos[i].replace('.pdf', '')}.{j+1}.txt\"), 'w') as f:\n",
    "                    f.write(tab_by_regex(page))\n",
    "    \n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "##                                    \n",
    "\n",
    "@timing.time_log()\n",
    "def extract_dates(\n",
    "    x: Dict[str, List[str]], \n",
    "    exclude_date: Optional[str] = None\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "        Busca las fechas en un diccionario del siguiente formato :\n",
    "            { str: Dict[str, List[str]] }\n",
    "            \n",
    "        Genera un diccionario con las mismas llaves, pero con una lista \n",
    "        de las fechas que encontró en las hojas (cada uno de los strings \n",
    "        dentro de la lista).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    dates = {}\n",
    "    for nombre, lista in x.items():\n",
    "        _tmp_list = []\n",
    "        for string in lista:\n",
    "            _tmp_list += list(set(\n",
    "                regex.findall(r\"(\\d{2}\\D[A-Z]{3}\\D\\d{4}|\\d{2}\\D\\d{2}\\D\\d{4})\", string)\n",
    "            ))\n",
    "        dates.update({\n",
    "            nombre: list(set(_tmp_list))\n",
    "        })\n",
    "\n",
    "    if exclude_date is not None:\n",
    "        for nombre, lista in dates.items():\n",
    "            dates[nombre] = list(\n",
    "                filter(lambda x: x if x != exclude_date else False, lista)\n",
    "            )\n",
    "    \n",
    "    return dates\n",
    "##\n",
    "                                       \n",
    "@timing.time_log()\n",
    "def save_to_jsonl(x: Dict[str, List[str]], filename: Optional[str] = None) -> bool:\n",
    "    \"\"\"\n",
    "        Guarda los resultados en un archivo, cuyo nombre puede \n",
    "        ser opcionalmente especificado a través del parámetro 'filename'.\n",
    "        \n",
    "        El NOMBRE por defecto es :\n",
    "            'resultados.jl'\n",
    "            \n",
    "        El nombre del archivo 'filename' puede ser un camino absoluto, si\n",
    "        se desea guardar la información en algún otro lugar.\n",
    "        \n",
    "        POR DEFECTO se trata del mismo directorio :\n",
    "            En la línea de comando :\n",
    "                `pwd`\n",
    "                \n",
    "            Desde Python :\n",
    "                os.path.abspath('.')\n",
    "        \n",
    "        El formato de registro es JSON-lines :\n",
    "            http://jsonlines.org/\n",
    "            \n",
    "        El modo de edición del archivo es 'append', \n",
    "        es decir los nuevos registros se añaden, sin borrar \n",
    "        las líneas anteriores.\n",
    "        \n",
    "        Prámetros :\n",
    "                   x: Diccionario { str: List[str] }, la información por guardar.\n",
    "            filename: Opcional, str, nombre del archivo de registro.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        _archivos = x.keys()\n",
    "        if filename is None:\n",
    "            filename = 'resultados.jl'\n",
    "                                       \n",
    "        with open(filename, 'a') as f:\n",
    "            for archivo in _archivos:\n",
    "                for hoja in x[archivo]:\n",
    "                    f.write(f\"{json.dumps(dict_from_regex(hoja))}\\n\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "##\n",
    "\n",
    "@timing.time_log()                                     \n",
    "def build_string_from_dict(x: Union[Dict[str, List[str]], List[Dict[str, Any]]]) -> str:\n",
    "    ''' \n",
    "        Construye una cadena de caracteres a partir de una de\n",
    "        dos posibles estructuras anidadas :\n",
    "        \n",
    "        1. Diccionario :  {   str: List[str] }\n",
    "        2. Lista       :  [ { str: Any }     ]\n",
    "        \n",
    "        Esta cadena de caracteres es óptima para la visualización.\n",
    "    '''\n",
    "    newline = lambda x: f\"{x}\\n\"\n",
    "    ntab = lambda n, txt: n*\"\\t\" + txt\n",
    "                                       \n",
    "    my_string = ''\n",
    "    \n",
    "    if type(x) is list:\n",
    "        for entry in x:\n",
    "            for key in entry.keys():\n",
    "                my_string += f'{key}: {entry[key]}\\n'\n",
    "            my_string += '\\n\\n'\n",
    "    elif type(x) is dict:\n",
    "        for key1, value in x.items():\n",
    "            my_string += f\"{key1}:\\n\"\n",
    "            for key2 in value.keys():\n",
    "                my_string += f'\\t{key2}: {value[key2]}\\n'\n",
    "            my_string += '\\n\\n'\n",
    "                                       \n",
    "    \n",
    "    return my_string\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type({}) is dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline = lambda x: f\"{x}\\n\"\n",
    "ntab = lambda n, txt: n*\"\\t\" + txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gml/Documents/IX/imagenes/FinalDeImagenes/analisis_clinicos'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.abspath('analisis_clinicos/')\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se encuentran todos los pdf con análisis clínicos que tenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gml/Documents/IX/imagenes/FinalDeImagenes/textos'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_textos = os.path.abspath('textos')\n",
    "path_textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta dirección guardaremos todos los textos reconocidos por **pytesseract**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminos_textos = glob.glob(f\"{path_textos}/*.txt\")\n",
    "caminos_textos.sort()\n",
    "#caminos_textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta dirección se almacenaron los textos que se extrajeron de los documentos a partir de **pytesseract**. Nótese que al procesar imagen por imagen, y al crear nosotros una imagen por cada página del pdf, los nombres que ahí se encuentran son los originales, sin la extensión pdf, con un punto indicando el nombre de página y con terminación txt.\n",
    "\n",
    "```mi_archivo.pdf```  => ```mi_archivo.i.txt``` Donde **i** indica el número de página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminos = glob.glob(f\"{path}/*.pdf\")\n",
    "#caminos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta lista contiene el camino hacia cada uno de los PDFs de los cuales se desean extraer los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13.pdf',\n",
       " 'gustavo_maganna_2018-05-06.pdf',\n",
       " 'gustavo_maganna_2019-11-13.pdf',\n",
       " 'Wed Nov 13 18:05:58 CST 2019.pdf',\n",
       " 'InformeResultados1-110600.pdf',\n",
       " 'gustavo_maganna_2018-01-19.pdf']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivos = [ os.path.split(camino)[1] for camino in caminos]\n",
    "archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de los archivos PDF, sin el camino absoluto dentro del *filesystem*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13',\n",
       " 'gustavo_maganna_2018-05-06',\n",
       " 'gustavo_maganna_2019-11-13',\n",
       " 'Wed Nov 13 18:05:58 CST 2019',\n",
       " 'InformeResultados1-110600',\n",
       " 'gustavo_maganna_2018-01-19']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres = [ archivo.replace('.pdf', '') for archivo in archivos ]\n",
    "nombres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de los archivos, sin la extensión ```.pdf```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahora_si = { \n",
    "    archivo: glob.glob(os.path.join(path_textos ,f\"{nombre}.?.txt\")) \n",
    "    for archivo, nombre in zip(archivos, nombres)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ ahora_si[key].sort() for key in ahora_si.keys() ]\n",
    "#ahora_si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_from_txt = True\n",
    "\n",
    "if parse_from_txt:\n",
    "    # Buscamos todos los archivos de texto :\n",
    "    #   los nombres de archivo especificados por 'nombres'\n",
    "    #   en el directorio especificado por 'path_textos'\n",
    "    archivos_de_texto = { \n",
    "        archivo: glob.glob(os.path.join(path_textos ,f\"{nombre}.?.txt\")) \n",
    "        for archivo, nombre in zip(archivos, nombres)\n",
    "    }\n",
    "    # Los ordenamos, para que el orden de las páginas sea el mismo \n",
    "    # que en los PDFs :\n",
    "    [ archivos_de_texto[key].sort() for key in archivos_de_texto.keys() ]\n",
    "    \n",
    "    # Creamos un diccionario vacío el cual contendrá todas las cadenas \n",
    "    # de acaracteres asociadas a cada una de las hojas de cada uno de los reportes\n",
    "    # de análisis clínicos.\n",
    "    strings = {}\n",
    "    \n",
    "    # Iteramos sobre cada uno de los nombres de archivo pdf\n",
    "    for key in archivos_de_texto.keys():\n",
    "        # Generamos una lista vacía para contener las 'n'\n",
    "        # cadenas de caracteres, correspondientes a las 'n'\n",
    "        # páginas de cada pdf.\n",
    "        _strings = []\n",
    "        for _file in archivos_de_texto[key]:\n",
    "            # Iteramos sobre cada 'hoja' perteneciente al pdf especificado.\n",
    "            with open(_file, 'r') as f:\n",
    "              _strings.append(f.read())\n",
    "        strings.update({\n",
    "            # Añadimos el archivo como llave y \n",
    "            # la lista de strings como valor al diccionario.\n",
    "            key: _strings\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain text from the PDFs, directly (this takes about a minute) : \n",
    "from_pdfs = False\n",
    "\n",
    "if from_pdfs:\n",
    "    # Para acelerar el proceso, generamos imágenes de forma paralela\n",
    "    # gracias a pool.map :\n",
    "    imagenes = pool.map(convert_from_path, caminos)\n",
    "    # Construimos un diccionario con los nombres de archivos y las\n",
    "    # imágenes obtenidas : \n",
    "    archivos_en_imagenes = {\n",
    "        archivo: imagen for archivo, imagen in zip(archivos, imagenes)\n",
    "    }\n",
    "    # Generamos un nuevo diccionario, ahora con cadenas de caracteres\n",
    "    # en lugar de imágenes, estas primeras obtenidas a través de \n",
    "    # pytesseract.\n",
    "    # la función images_to_strings() utiliza a su vez pool.map, para\n",
    "    # acelerar el proceso de extracción de caracteres.\n",
    "    strings = images_to_strings(archivos_en_imagenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos cada uno de los strings generados, \n",
    "# para poder posteriormente acceder a ellos sin necesidad de \n",
    "# repetir el procesamiento de imágenes, lo que conforme \n",
    "# crezca la base de datos del PDF, se hará más lento.\n",
    "save = True\n",
    "\n",
    "if save:\n",
    "    for nombre, hojas in strings.items():\n",
    "        for i, hoja in enumerate(hojas):\n",
    "            _file_name = os.path.join(path_textos, f\"{nombre.replace('.pdf', '')}.{i+1}.txt\")\n",
    "            with open(_file_name, \"w\") as f:\n",
    "                f.write(hoja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gustavo_maganna_2018-05-13.pdf': ['13/05/2018'],\n",
       " 'gustavo_maganna_2018-05-06.pdf': [],\n",
       " 'gustavo_maganna_2019-11-13.pdf': ['13-NOV-2019'],\n",
       " 'Wed Nov 13 18:05:58 CST 2019.pdf': ['13-NOV-2019'],\n",
       " 'InformeResultados1-110600.pdf': ['15-NOV-2019'],\n",
       " 'gustavo_maganna_2018-01-19.pdf': ['19-ENE-2018']}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_dates(strings, exclude_date='06/08/1996')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función que creamos ```extract_date()``` permite obtener fechas encontradas en un PDF, con flexibilidad en cuanto a formatos y la posibilidad de excluir una fecha especificada, que bien podría ser la fecha de cumpleaños del paciente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARANDA DE LA PARRA DIR. (477) 719-71-02 CONM. 719-71-00 EXT. 143 Y 145 TEL/FAX: 713-33-03\n",
      "\tARANDA DE LA PARRA DIR\n",
      "\t\t477\n",
      "\t\t719\n",
      "\t\t71\n",
      "\t\t02\n",
      "\t\t719\n",
      "\t\t71\n",
      "\t\t00\n",
      "\t\t143\n",
      "\t\t145\n",
      "\t\t713\n",
      "\t\t33\n",
      "\t\t03\n",
      "\t\t\t CONM.\n",
      "\t\t\t EXT.\n",
      "\t\t\t Y\n",
      "\t\t\t TEL/FAX:\n",
      "HEMOGLOBINA........0ccccceeeeeeeeeeeee 16.9 g/dL t 14.10 - 16.30\n",
      "\tHEMOGLOBINA.\n",
      "\t\t0\n",
      "\t\t16.9\n",
      "\t\t14.10\n",
      "\t\t16.30\n",
      "\t\t\tccccceeeeeeeeeeeee\n",
      "\t\t\t g/dL\n",
      "\t\t\t -\n",
      "HEMATOCRITO. 48.0 % tT 41-47\n",
      "\tHEMATOCRITO\n",
      "\t\t48.0\n",
      "\t\t41\n",
      "\t\t47\n",
      "\t\t\t %\n",
      "V.C.M.... 86.2 fL 84 - 94\n",
      "\tV.C.M.\n",
      "\t\t86.2\n",
      "\t\t84\n",
      "\t\t94\n",
      "\t\t\t fL\n",
      "\t\t\t -\n",
      "LEUCOCITOS.......cccccecceecneeeeeeeeee 5.9 Mil/microL 5.30 - 9.50\n",
      "\tLEUCOCITOS.\n",
      "\t\t5.9\n",
      "\t\t5.30\n",
      "\t\t9.50\n",
      "\t\t\t Mil/microL\n",
      "\t\t\t -\n",
      "PLAQUETAS.......0ccccccceeee tsetse 163 Mil/microL 150 - 450\n",
      "\tPLAQUETAS.\n",
      "\t\t0\n",
      "\t\t163\n",
      "\t\t150\n",
      "\t\t450\n",
      "\t\t\tccccccceeee\n",
      "\t\t\t Mil/microL\n",
      "\t\t\t -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tab_by_regex(strings[archivos[1]][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí observamos cómo la función que definimos ```tab_by_regex()``` puede identficar correctamente los parámetros de interés, aunque incluye datos que pueden no ser los deseados ya que el reconocimiento de caracteres de **pytesseract** no es perfecto.\n",
    "\n",
    "Esto se deberá tomar en cuenta el momento de generar los registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPURACION DE CREATININA.:\n",
      "\tvalues: [133.6, 75.0, 115.0]\n",
      "\tunits: [' mL/min']\n",
      "\n",
      "\n",
      "CREATININA.:\n",
      "\tvalues: [0.92, 0.61, 1.24]\n",
      "\tunits: [' mg/dL', ' -']\n",
      "\n",
      "\n",
      "CREATININA URINARIA:\n",
      "\tvalues: [82.6, 39.0, 259.0]\n",
      "\tunits: [' mg/dL', ' -']\n",
      "\n",
      "\n",
      "SUP:\n",
      "\tvalues: [1.86, 2.0]\n",
      "\tunits: []\n",
      "\n",
      "\n",
      "MICROALBUMINURIA.:\n",
      "\tvalues: [10.0, 0.0, 100.0]\n",
      "\tunits: [' mg/L']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ejemplo = dict_from_regex(strings['gustavo_maganna_2018-01-19.pdf'][0])\n",
    "print(build_string(ejemplo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_to_jsonl(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guarda(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13',\n",
       " 'gustavo_maganna_2018-05-06',\n",
       " 'gustavo_maganna_2019-11-13',\n",
       " 'Wed Nov 13 18:05:58 CST 2019',\n",
       " 'InformeResultados1-110600',\n",
       " 'gustavo_maganna_2018-01-19']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gustavo_maganna_2018-05-06.pdf\n",
      "5\n",
      "LABORATORIO DE PATOLOGIA CLINICA\n",
      "\n",
      "HOSPITAL AVENIDA HIDALGO No 329 C.P. : 37000 LEON, GTO.\n",
      "ARANDA DE LA PARRA DIR. (477) 719-71-02 CONM. 719-71-00 EXT. 143 Y 145 TEL/FAX: 713-33-03\n",
      "TODA LA VIDA CONTIGO\n",
      "Paciente: GUSTAVO MAGANA LOPEZ Edad: 21 ANOS Sexo: MASCULINO — Cuarto — Cama:\n",
      "Expediente: Folio: 028028 Seccion: EXTERNO\n",
      "Fecha Nac.:06/08/1996 Fecha ingreso: 6-MAY-2018 09:20 AM_ Fecha—Hora ler Impresion:6-MAY-2018 01:34 PM\n",
      "\n",
      "Médico:JUAN CARLOS FERRER SERRANO Procedencia: H. ARANDA DE LA\n",
      "\n",
      "Ultima Impresion: 6-MAY-2018 07:58 PM\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "PARRA\n",
      ". U. de :\n",
      "Estudio Resultado Medida Intervalo de Referencia\n",
      "PERFIL DE LIPIDOS\n",
      "COLESTEROL....sssssssssssssssesssssssseeeeees 118 mg/dL | 140 - 200 v\n",
      "< 150 Normal\n",
      "TRIGLICERIDOS ....csscsscssessenseesee 50 mg/dL 300-500 Noe v\n",
      ">500 Muy Alto\n",
      "VLDL COLESTEROL.....s-:ssccssssssseeeeeee 10 mg/dL 5-35\n",
      "< 100 Optimo |\n",
      "LDL COLESTEROL...sscssssssssessssesenee 72 mg/dL 130. 169 Lenwnte ato v\n",
      "160 - 189 Alto\n",
      ">= 190 Muy Alto\n",
      "INDICE DE RIESGO CORONARIO\n",
      "HDL COLESTEROL.......csssccsssseeeesseee 33 mg/dL IEERMEDIO. cases v\n",
      "ALTO... MENOR A 35,\n",
      "LIPIDOS TOTALES......:ssssssscsseeesssesseees 337 mg/dL | 450 - 1000\n",
      "INDICE ATEROGENICO... 3.6 RiEScO INTERMEDIO: 4.5 -8\n",
      "\n",
      " \n",
      "\n",
      "METODOLOGIA: ESPECTROFOTOMETRIA AUTOMATIZADA\n",
      "TIPO DE MUESTRA: SUERO\n",
      "\n",
      "NOTA: Este reporte no constituye un diagndstico. Consulte a su médico.\n",
      "\n",
      "Responsable sanitario: Dr. Gilberto Aguilar Orozco, Patélogo Clinico, U.A.N.L.\n",
      "\n",
      "Céd. Prof. 1186314. Registro de especialista SSG 1294 SEP: Autorizacion AE-003261.\n",
      "\n",
      "El laboratorio tiene a su disposiciOn la verificacion de la validacion del método,\n",
      "\n",
      "en caso que desee consultarlo.\n",
      "\n",
      "Aviso: Si requiere que los resultados sean emitidos en Unidades Internacionales,\n",
      "\n",
      "favor de solicitarlo al laboratorio.\n",
      "\n",
      "Laboratorio Clinico acreditado por ema, a.c. con acreditacion No CL-078. Las pruebas en el alcance\n",
      "\n",
      "de la acreditacién estan identificadas con el simbolo V\n",
      "\n",
      "RIESGO BAJO: < 4.5\n",
      "\n",
      "Atentamente\n",
      "\n",
      "Dr. Gilberto Aguilar Orozco.\n",
      "\n",
      "Pagina 3 de 5\n"
     ]
    }
   ],
   "source": [
    "_file = archivos[1]\n",
    "print(_file)\n",
    "print(len(strings[_file]))\n",
    "print(strings[_file][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor line in foo_lines:\\n    for i in regex.finditer(r\"[0a-z]{2,}\", line):\\n        print(foo_lines[14])\\n        #print(i.string)\\n        #print(\\'\\t\\', i.group())\\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = strings[_file][2]\n",
    "\n",
    "# Split by line breaks :\n",
    "foo_lines = foo.split(\"\\n\")\n",
    "\n",
    "# Select valid lines (i.e. longer than 5 characters) :\n",
    "foo_lines = [ line for line in foo_lines ] # if len(line) > 1 ]\n",
    "\n",
    "#regex.compile(r'[A-Z]')\n",
    "print(foo_lines[10])\n",
    "print(foo_lines[14])\n",
    "\"\"\"\n",
    "for line in foo_lines:\n",
    "    for i in regex.finditer(r\"[0a-z]{2,}\", line):\n",
    "        print(foo_lines[14])\n",
    "        #print(i.string)\n",
    "        #print('\\t', i.group())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tab_by_regex(strings[archivos[2]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13',\n",
       " 'gustavo_maganna_2018-05-06',\n",
       " 'gustavo_maganna_2019-11-13',\n",
       " 'Wed Nov 13 18:05:58 CST 2019',\n",
       " 'InformeResultados1-110600',\n",
       " 'gustavo_maganna_2018-01-19']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13.pdf',\n",
       " 'gustavo_maganna_2018-05-06.pdf',\n",
       " 'gustavo_maganna_2019-11-13.pdf',\n",
       " 'Wed Nov 13 18:05:58 CST 2019.pdf',\n",
       " 'InformeResultados1-110600.pdf',\n",
       " 'gustavo_maganna_2018-01-19.pdf']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gml/Documents/IX/imagenes/FinalDeImagenes/segmented'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camino_resultados = os.path.abspath('segmented')\n",
    "camino_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'hue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-5bbae95ba4ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'hue'"
     ]
    }
   ],
   "source": [
    "os.mkdir('hue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, archivo in enumerate(archivos):\n",
    "    for j, page in enumerate(strings[archivo]):\n",
    "        with open(os.path.join(camino_resultados, f\"{nombres[i]}.{j+1}.txt\"), 'w') as f:\n",
    "            f.write(tab_by_regex(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline = lambda x: f\"{x}\\n\"\n",
    "ntab = lambda n, txt: n*\"\\t\" + txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'COL': {'values': [], 'units': []}, 'DRA': {'values': [], 'units': []}}\n",
      "{'AV': {'values': [311.0], 'units': []}, 'COL': {'values': [], 'units': []}, 'DRA': {'values': [], 'units': []}}\n",
      "{'COL': {'values': [], 'units': []}, 'POBLACION ABIERTA': {'values': [], 'units': []}}\n",
      "{'HEMATOCRITO': {'values': [48.0, 41.0, 47.0], 'units': [' %']}, 'V': {'values': [86.2, 84.0, 94.0], 'units': [' fL', ' -']}, 'LEUCOCITOS': {'values': [5.9, 5.3, 9.5], 'units': [' Mil/microL', ' -']}}\n",
      "{'GLUCOSA': {'values': [68.0, 70.0, 100.0], 'units': [' mg/dL', ' -']}, 'CREATININA': {'values': [0.76, 0.61, 1.24], 'units': [' mg/dL', ' -']}, 'ACIDO URICO': {'values': [4.9, 4.8, 8.7], 'units': [' mg/dL', ' -']}, 'HEMOGLOBINA GLICOSILADA': {'values': [6.7, 4.5, 6.3], 'units': [' %', ' -']}}\n",
      "{'COLESTEROL': {'values': [118.0, 140.0, 200.0], 'units': [' mg/dL', ' -']}, 'TRIGLICERIDOS ': {'values': [50.0, 300.0, 500.0], 'units': [' mg/dL', ' Noe']}, 'VLDL COLESTEROL': {'values': [10.0, 5.0, 35.0], 'units': [' mg/dL']}, 'LDL COLESTEROL': {'values': [72.0, 130.0, 169.0], 'units': [' mg/dL', ' Lenwnte']}, 'HDL COLESTEROL': {'values': [33.0], 'units': [' mg/dL']}, 'ALTO': {'values': [35.0], 'units': []}, 'LIPIDOS TOTALES': {'values': [337.0, 450.0, 1000.0], 'units': [' mg/dL', ' -']}, 'INDICE ATEROGENICO': {'values': [3.6, 4.5, 8.0], 'units': [' RiEScO']}}\n",
      "{'BILIRRUBINA DIRECTA': {'values': [0.25, 0.1, 0.5], 'units': [' mg/dL', ' -']}, 'PROTEINAS TOTALES': {'values': [73.0, 6.5, 8.1], 'units': [' g/dL', ' -']}, 'FOSFATASA ALCALINA': {'values': [42.0, 32.0, 91.0], 'units': [' UIL']}, 'GAMA GLUTAMIL TRANSFERASA': {'values': [13.0, 7.0, 50.0], 'units': [' UIL']}}\n",
      "{'VOLUMEN': {'values': [30.0], 'units': []}, 'COLOR': {'values': [], 'units': []}, 'ASPECTO': {'values': [], 'units': []}, 'GLUCOSA': {'values': [100.0], 'units': [' mg/dL']}, 'PROTEINAS': {'values': [20.0], 'units': [' mg/dL']}, 'HEMOGLOBINA': {'values': [], 'units': []}, 'PIG': {'values': [], 'units': []}, 'ESTERASA LEUCOCITARIA': {'values': [], 'units': []}, 'UROBILINOGENO': {'values': [0.2, 0.2], 'units': [' mg/dL']}, 'LEUCOCITOS': {'values': [1.0, 0.0, 3.0], 'units': [' CAMPO']}, 'ERITROCITOS': {'values': [1.0, 0.0, 3.0], 'units': [' CAMPO']}, 'CRISTALES': {'values': [], 'units': []}, 'CILINDROS': {'values': [], 'units': []}, 'CELS': {'values': [], 'units': []}, 'BACTERIAS': {'values': [], 'units': []}, 'LEVADURAS': {'values': [], 'units': []}}\n",
      "{'GLUCOSA': {'values': [139.0, 60.0, 100.0], 'units': [' mg/dL', ' -']}, 'HEMOGLOBINA GLICOSILADA': {'values': [7.2, 3.8, 6.4], 'units': [' %', ' -']}}\n",
      "{'COLESTEROL': {'values': [152.0], 'units': [' mg/dL']}, 'VLDL COLESTEROL': {'values': [7.0, 5.0, 35.0], 'units': [' mg/dL']}, 'LDL COLESTEROL': {'values': [91.0, 130.0, 159.0], 'units': [' mg/dL.', ' Limite']}, 'BAJO': {'values': [55.0], 'units': []}, 'HDL COLESTEROL': {'values': [56.0, 35.0, 55.0], 'units': [' mg/dL']}, 'ALTO': {'values': [35.0], 'units': []}, 'LIPIDOS TOTALES': {'values': [362.0, 450.0, 1000.0], 'units': [' mg/dL', ' -']}, 'INDICE ATEROGENICO': {'values': [0.0, 27.0], 'units': [' RESO']}}\n",
      "{'VOLUMEN': {'values': [50.0], 'units': []}, 'GLUCOSA ': {'values': [50.0], 'units': [' mg/dL']}, 'PROTEINAS': {'values': [], 'units': []}, 'ACETONA': {'values': [], 'units': []}, 'HEMOGLOBINA': {'values': [], 'units': []}, 'PIG': {'values': [], 'units': []}, 'ESTERASA LEUCOCITARIA': {'values': [], 'units': []}, 'UROBILINOGENO': {'values': [0.2, 0.2], 'units': [' mg/dL']}, 'LEUCOCITOS': {'values': [1.0, 0.0, 3.0], 'units': [' CAMPO']}, 'ERITROCITOS': {'values': [1.0, 0.0, 3.0], 'units': [' CAMPO']}, 'CRISTALES': {'values': [], 'units': []}, 'CILINDROS': {'values': [], 'units': []}, 'CELS': {'values': [], 'units': []}, 'BACTERIAS': {'values': [], 'units': []}}\n",
      "{'GLUCOSA': {'values': [139.0, 60.0, 100.0], 'units': [' mg/dL', ' -']}, 'HEMOGLOBINA GLICOSILADA': {'values': [7.2, 3.8, 6.4], 'units': [' %', ' -']}}\n",
      "{'COLESTEROL': {'values': [152.0], 'units': [' mg/dL']}, 'VLDL COLESTEROL': {'values': [7.0, 5.0, 35.0], 'units': [' mg/dL']}, 'LDL COLESTEROL': {'values': [91.0, 130.0, 159.0], 'units': [' mg/dL.', ' Limite']}, 'BAJO': {'values': [55.0], 'units': []}, 'HDL COLESTEROL': {'values': [56.0, 35.0, 55.0], 'units': [' mg/dL']}, 'ALTO': {'values': [35.0], 'units': []}, 'LIPIDOS TOTALES': {'values': [362.0, 450.0, 1000.0], 'units': [' mg/dL', ' -']}, 'INDICE ATEROGENICO': {'values': [0.0, 27.0], 'units': [' RESO']}}\n",
      "{'VOLUMEN': {'values': [50.0], 'units': []}, 'GLUCOSA ': {'values': [50.0], 'units': [' mg/dL']}, 'PROTEINAS': {'values': [], 'units': []}, 'ACETONA': {'values': [], 'units': []}, 'HEMOGLOBINA': {'values': [], 'units': []}, 'PIG': {'values': [], 'units': []}, 'ESTERASA LEUCOCITARIA': {'values': [], 'units': []}, 'UROBILINOGENO': {'values': [0.2, 0.2], 'units': [' mg/dL']}, 'LEUCOCITOS': {'values': [1.0, 0.0, 3.0], 'units': [' CAMPO']}, 'ERITROCITOS': {'values': [1.0, 0.0, 3.0], 'units': [' CAMPO']}, 'CRISTALES': {'values': [], 'units': []}, 'CILINDROS': {'values': [], 'units': []}, 'CELS': {'values': [], 'units': []}, 'BACTERIAS': {'values': [], 'units': []}}\n",
      "{'INDICE DE TIROXINA LIBRE': {'values': [7.98, 5.06, 9.42], 'units': [' g/dL', ' -']}}\n",
      "{'DEPURACION DE CREATININA': {'values': [133.6, 75.0, 115.0], 'units': [' mL/min']}, 'CREATININA': {'values': [0.92, 0.61, 1.24], 'units': [' mg/dL', ' -']}, 'CREATININA URINARIA': {'values': [82.6, 39.0, 259.0], 'units': [' mg/dL', ' -']}, 'SUP': {'values': [1.86, 2.0], 'units': []}, 'MICROALBUMINURIA': {'values': [10.0, 0.0, 100.0], 'units': [' mg/L']}}\n"
     ]
    }
   ],
   "source": [
    "for archivo in archivos:\n",
    "    for hoja in strings[archivo]:\n",
    "        print(dict_from_regex(hoja))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_my_str = ''\n",
    "for line in foo_lines:\n",
    "    for i in regex.finditer(r\"^([A-Z\\s]|[A-Z]\\.?)+?(?=(\\..+))\", line): # FIND lines starting with Caps \n",
    "        _my_str += newline(i.string)\n",
    "        _my_str += newline(ntab(1, i.group()))\n",
    "        for j in regex.finditer(r\"(\\d+\\.\\d+|\\d+)\", i.string): # find groups of numbers\n",
    "            _my_str += newline(ntab(2, j.group()))\n",
    "        for k in regex.finditer(r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\d]+?(?=\\s)\", i.string):\n",
    "            _my_str += newline(ntab(3, k.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARANDA DE LA PARRA DIR. (477) 719-71-02 CONM. 719-71-00 EXT. 143 Y 145 TEL/FAX: 713-33-03\n",
      "\tARANDA DE LA PARRA DIR\n",
      "\t\t477\n",
      "\t\t719\n",
      "\t\t71\n",
      "\t\t02\n",
      "\t\t719\n",
      "\t\t71\n",
      "\t\t00\n",
      "\t\t143\n",
      "\t\t145\n",
      "\t\t713\n",
      "\t\t33\n",
      "\t\t03\n",
      "\t\t\t CONM.\n",
      "\t\t\t EXT.\n",
      "\t\t\t Y\n",
      "\t\t\t TEL/FAX:\n",
      "COLESTEROL....sssssssssssssssesssssssseeeeees 118 mg/dL | 140 - 200 v\n",
      "\tCOLESTEROL\n",
      "\t\t118\n",
      "\t\t140\n",
      "\t\t200\n",
      "\t\t\t mg/dL\n",
      "\t\t\t -\n",
      "TRIGLICERIDOS ....csscsscssessenseesee 50 mg/dL 300-500 Noe v\n",
      "\tTRIGLICERIDOS \n",
      "\t\t50\n",
      "\t\t300\n",
      "\t\t500\n",
      "\t\t\t mg/dL\n",
      "\t\t\t Noe\n",
      "VLDL COLESTEROL.....s-:ssccssssssseeeeeee 10 mg/dL 5-35\n",
      "\tVLDL COLESTEROL\n",
      "\t\t10\n",
      "\t\t5\n",
      "\t\t35\n",
      "\t\t\t mg/dL\n",
      "LDL COLESTEROL...sscssssssssessssesenee 72 mg/dL 130. 169 Lenwnte ato v\n",
      "\tLDL COLESTEROL\n",
      "\t\t72\n",
      "\t\t130\n",
      "\t\t169\n",
      "\t\t\t mg/dL\n",
      "\t\t\t Lenwnte\n",
      "HDL COLESTEROL.......csssccsssseeeesseee 33 mg/dL IEERMEDIO. cases v\n",
      "\tHDL COLESTEROL\n",
      "\t\t33\n",
      "\t\t\t mg/dL\n",
      "ALTO... MENOR A 35,\n",
      "\tALTO\n",
      "\t\t35\n",
      "LIPIDOS TOTALES......:ssssssscsseeesssesseees 337 mg/dL | 450 - 1000\n",
      "\tLIPIDOS TOTALES\n",
      "\t\t337\n",
      "\t\t450\n",
      "\t\t1000\n",
      "\t\t\t mg/dL\n",
      "\t\t\t -\n",
      "INDICE ATEROGENICO... 3.6 RiEScO INTERMEDIO: 4.5 -8\n",
      "\tINDICE ATEROGENICO\n",
      "\t\t3.6\n",
      "\t\t4.5\n",
      "\t\t8\n",
      "\t\t\t RiEScO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor line in foo_lines:\\n    for i in regex.finditer(r\"^([A-Z\\\\s]|[A-Z]\\\\.?)+?(?=(\\\\..+))\", line): # FIND lines starting with Caps \\n        print(i.string)\\n        print(\\'\\t\\',i.group())\\n        for j in regex.finditer(r\"(\\\\d+\\\\.\\\\d+|\\\\d+)\", i.string): # find groups of numbers\\n            print(2*\\'\\t\\',j.group())\\n        for k in regex.finditer(r\"(?<=(\\\\d+\\\\.\\\\d+|\\\\d+))\\\\D[^\\\\d]+?(?=\\\\s)\", i.string):\\n            print(3*\\'\\t\\',k.group())\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for line in foo_lines:\n",
    "    for i in regex.finditer(r\"^([A-Z\\s]|[A-Z]\\.?)+?(?=(\\..+))\", line): # FIND lines starting with Caps \n",
    "        print(i.string)\n",
    "        print('\\t',i.group())\n",
    "        for j in regex.finditer(r\"(\\d+\\.\\d+|\\d+)\", i.string): # find groups of numbers\n",
    "            print(2*'\\t',j.group())\n",
    "        for k in regex.finditer(r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\d]+?(?=\\s)\", i.string):\n",
    "            print(3*'\\t',k.group())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My regexps :\n",
    "\n",
    "my_may_ge_2 = r\"^[A-Z]{2,}\"  # Find CAPITAL WORDS longer than 2, at the begining of the line.\n",
    "my_numbers = r\"(\\d+\\.\\d+|\\d+)\" # Find numbers of any length, with a decimal point or not.\n",
    "my_from_begining_until_point = r\"^.+?(?=(\\..+))\" # Find any text before the first occurrence of a pint\n",
    "my_caps_and_whitespace_until_point = r\"^[A-Z\\s]+?(?=(\\..+))\"\n",
    "my_caps_and_whitspace_or_acronym_until_point = r\"^([A-Z\\s|[A-Z]\\.?)+?(?=(\\..+))\"\n",
    "my_failed_extract_units = r\"(?<=((\\d+\\.\\d+|\\d+)+))(.+)\"\n",
    "googled_text_between_brackets = r\"(?<=\\[).+?(?=\\])\"\n",
    "my_extract_units = r\"(?<=(\\d+\\.\\d+|\\d+))\\D+?(?=(\\d+\\.\\d+|\\d+))\"\n",
    "my_better_extract_units_between_numbers = r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\.\\d]+?(?=(\\d+\\.\\d+|\\d+))\"\n",
    "my_extract_units_between_numbers_and_whitespace = r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\.\\d]+?(?=\\s)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function purge in module regex.regex:\n",
      "\n",
      "purge()\n",
      "    Clear the regular expression cache\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir(regex)\n",
    "help(regex.purge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'foo_lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-6a4e68ef1b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfoo_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^[A-Z]{2,}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'foo_lines' is not defined"
     ]
    }
   ],
   "source": [
    "for line in foo_lines:\n",
    "    for i in regex.findall(r\"^[A-Z]{2,}\", line):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"\\n hola \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n hola \\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"{}\".format(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n\\nhola\n"
     ]
    }
   ],
   "source": [
    "print(r'\\n\\nhola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('watever', 'w') as lol:\n",
    "    lol.write(strings[archivos[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'page' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-95d6aff11d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m caracteres_por_linea = pd.core.series.Series(\n\u001b[1;32m      3\u001b[0m     [\n\u001b[0;32m----> 4\u001b[0;31m      \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mpdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'page' is not defined"
     ]
    }
   ],
   "source": [
    "# Cuántas líneas tenemos en total :\n",
    "caracteres_por_linea = pd.core.series.Series(\n",
    "    [\n",
    "     len(line) for line in page.split('\\n') \n",
    "     for pdf in strings \n",
    "     for page in pdf\n",
    "    ],\n",
    "    name='caracteres'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'caracteres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-af66243ab376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaracteres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'caracteres' is not defined"
     ]
    }
   ],
   "source": [
    "sns.distplot(caracteres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
