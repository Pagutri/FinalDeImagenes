{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex\n",
    "import glob\n",
    "import multiprocessing as mp\n",
    "import importlib\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "from typing import Tuple, Callable, Any, NoReturn, List, Dict, Optional\n",
    "\n",
    "from functools import partial, reduce\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pdf2image.exceptions import (\n",
    "    PDFInfoNotInstalledError,\n",
    "    PDFPageCountError,\n",
    "    PDFSyntaxError\n",
    ")\n",
    "\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timing\n",
    "importlib.reload(timing)\n",
    "import timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a multiprocess pool.\n",
    "pool = mp.Pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing.time_log()\n",
    "def images_to_strings(x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        nombre: pool.map(pytesseract.image_to_string, archivo) for nombre, archivo in x.items()\n",
    "    }\n",
    "##\n",
    "\n",
    "@timing.time_log()\n",
    "def tab_by_regex(x: str) -> str:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    newline = lambda x: f\"{x}\\n\"\n",
    "    ntab    = lambda n, txt: n*\"\\t\" + txt\n",
    "    \n",
    "    _x_lines: List[str] = x.split('\\n')\n",
    "    _my_str:  str       = ''\n",
    "        \n",
    "    for line in _x_lines:\n",
    "        # Match lines starting with Caps, separated by spaces or points : \n",
    "        for i in regex.finditer(r\"^([A-Z\\s]|[A-Z]\\.?)+?(?=(\\..+))\", line): \n",
    "            _my_str += newline(i.string)\n",
    "            _my_str += newline(ntab(1, i.group()))\n",
    "            # Match numbers, which could be either integers or floats : \n",
    "            for j in regex.finditer(r\"(\\d+\\.\\d+|\\d+)\", i.string): # find groups of numbers\n",
    "                _my_str += newline(ntab(2, j.group()))\n",
    "            # Match strings found between numbers :\n",
    "            for k in regex.finditer(r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\d]+?(?=\\s)\", i.string):\n",
    "                _my_str += newline(ntab(3, k.group()))\n",
    "    \n",
    "    return _my_str\n",
    "##\n",
    "\n",
    "@timing.time_log()\n",
    "def dict_from_regex(x: str) -> str:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    _x_lines: List[str] = x.split('\\n')\n",
    "    \n",
    "    _dict2 = {}\n",
    "    for line in _x_lines:\n",
    "        for i in regex.finditer(r\"^([A-Z\\s]|[A-Z]\\.?)+?(?=(\\..+))\", line): \n",
    "            i.group()\n",
    "            _valores = []\n",
    "            _unidades = []\n",
    "            for j in regex.finditer(r\"(\\d+\\.\\d+|\\d+)\", i.string): # find groups of numbers\n",
    "                _valores.append(float(j.group()))\n",
    "            for k in regex.finditer(r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\d]+?(?=\\s)\", i.string):\n",
    "                _unidades.append(k.group())\n",
    "            if len(_valores) < 4 and len(_unidades) < 4:\n",
    "                _dict2.update({\n",
    "                    i.group(): {\n",
    "                        \"values\": _valores,\n",
    "                        \"units\": _unidades\n",
    "                    }\n",
    "                })\n",
    "    \n",
    "    return _dict2\n",
    "##\n",
    "\n",
    "@timing.time_log()\n",
    "def save_results(x: Dict[str, List[str]]):\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if 'segmented' not in os.listdir('.'):\n",
    "            os.mkdir('segmented')\n",
    "        \n",
    "        _camino_resultados = os.path.abspath('segmented')\n",
    "        _archivos =  list(x.keys())\n",
    "    \n",
    "        for i, archivo in enumerate(_archivos):\n",
    "            for j, page in enumerate(x[archivo]):\n",
    "                with open(os.path.join(_camino_resultados, f\"{_archivos[i].replace('.pdf', '')}.{j+1}.txt\"), 'w') as f:\n",
    "                    f.write(tab_by_regex(page))\n",
    "    \n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "##                                    \n",
    "\n",
    "@timing.time_log()\n",
    "def extract_date(x: Dict[str, List[str]], exclude_date: Optional[str] = None):\n",
    "    dates = {}\n",
    "    for nombre, lista in x.items():\n",
    "        _tmp_list = []\n",
    "        for string in lista:\n",
    "            _tmp_list += list(set(\n",
    "                regex.findall(r\"(\\d{2}\\D[A-Z]{3}\\D\\d{4}|\\d{2}\\D\\d{2}\\D\\d{4})\", string)\n",
    "            ))\n",
    "        dates.update({\n",
    "            nombre: list(set(_tmp_list))\n",
    "        })\n",
    "\n",
    "    if exclude_date is not None:\n",
    "        for nombre, lista in dates.items():\n",
    "            dates[nombre] = lfilter(lambda x: x if x != exclude_date else False, lista)\n",
    "    \n",
    "    return dates\n",
    "##\n",
    "                                       \n",
    "@timing.time_log()\n",
    "def guarda(x, resultados: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        _archivos = x.keys()\n",
    "        if resultados is None:\n",
    "            resultados = 'resultados.jl'\n",
    "                                       \n",
    "        with open(resultados, 'a') as f:\n",
    "            for archivo in _archivos:\n",
    "                for hoja in x[archivo]:\n",
    "                    f.write(f\"{json.dumps(dict_from_regex(hoja))}\\n\")\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline = lambda x: f\"{x}\\n\"\n",
    "ntab = lambda n, txt: n*\"\\t\" + txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gml/Documents/IX/imagenes/FinalDeImagenes/analisis_clinicos'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.abspath('analisis_clinicos/')\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se encuentran todos los pdf con análisis clínicos que tenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gml/Documents/IX/imagenes/FinalDeImagenes/textos'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_textos = os.path.abspath('textos')\n",
    "path_textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta dirección guardaremos todos los textos reconocidos por **pytesseract**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminos_textos = glob.glob(f\"{path_textos}/*.txt\")\n",
    "caminos_textos.sort()\n",
    "#caminos_textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta dirección se almacenaron los textos que se extrajeron de los documentos a partir de **pytesseract**. Nótese que al procesar imagen por imagen, y al crear nosotros una imagen por cada página del pdf, los nombres que ahí se encuentran son los originales, sin la extensión pdf, con un punto indicando el nombre de página y con terminación txt.\n",
    "\n",
    "```mi_archivo.pdf```  => ```mi_archivo.i.txt``` Donde **i** indica el número de página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminos = glob.glob(f\"{path}/*.pdf\")\n",
    "#caminos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta lista contiene el camino hacia cada uno de los PDFs de los cuales se desean extraer los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13.pdf',\n",
       " 'gustavo_maganna_2018-05-06.pdf',\n",
       " 'gustavo_maganna_2019-11-13.pdf',\n",
       " 'Wed Nov 13 18:05:58 CST 2019.pdf',\n",
       " 'InformeResultados1-110600.pdf',\n",
       " 'gustavo_maganna_2018-01-19.pdf']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivos = [ os.path.split(camino)[1] for camino in caminos]\n",
    "archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de los archivos PDF, sin el camino absoluto dentro del *filesystem*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13',\n",
       " 'gustavo_maganna_2018-05-06',\n",
       " 'gustavo_maganna_2019-11-13',\n",
       " 'Wed Nov 13 18:05:58 CST 2019',\n",
       " 'InformeResultados1-110600',\n",
       " 'gustavo_maganna_2018-01-19']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres = [ archivo.replace('.pdf', '') for archivo in archivos ]\n",
    "nombres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de los archivos, sin la extensión ```.pdf```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahora_si = { \n",
    "    archivo: glob.glob(os.path.join(path_textos ,f\"{nombre}.?.txt\")) \n",
    "    for archivo, nombre in zip(archivos, nombres)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ ahora_si[key].sort() for key in ahora_si.keys() ]\n",
    "#ahora_si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pats = True\n",
    "\n",
    "if Pats:\n",
    "    strings = {}\n",
    "    for key in ahora_si.keys():\n",
    "        _strings = []\n",
    "        for _file in ahora_si[key]:\n",
    "            with open(_file, 'r') as f:\n",
    "              _strings.append(f.read())\n",
    "        strings.update({\n",
    "            key: _strings\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gus = True\n",
    "\n",
    "if Gus:\n",
    "    strings2 = {}\n",
    "    for key in ahora_si.keys():\n",
    "        _strings = []\n",
    "        for _file in ahora_si[key]:\n",
    "            with open(_file, 'r') as f:\n",
    "              _strings.append(f.read())\n",
    "        strings2.update({\n",
    "            key: _strings\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain text from the PDFs, directly (this takes about a minute) : \n",
    "from_scratch = False\n",
    "\n",
    "if from_scratch:\n",
    "    imagenes = pool.map(convert_from_path, caminos)\n",
    "    archivos_en_imagenes = {\n",
    "        archivo: imagen for archivo, imagen in zip(archivos, imagenes)\n",
    "    }\n",
    "    strings = images_to_strings(archivos_en_imagenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send all of these files to texts/\n",
    "save = False\n",
    "\n",
    "if save:\n",
    "    for nombre, hojas in strings.items():\n",
    "        for i, hoja in enumerate(hojas):\n",
    "            _file_name = os.path.join(path_textos, f\"{nombre.replace('.pdf', '')}.{i}.txt\")\n",
    "            with open(_file_name, \"w\") as f:\n",
    "                f.write(hoja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06/08/1996', '13/05/2018', '13/05/2018']\n",
      "['06/08/1996', '13/05/2018', '13/05/2018']\n",
      "['06/08/1996', '13/05/2018', '13/05/2018']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n",
      "['06/08/1996']\n"
     ]
    }
   ],
   "source": [
    "for lista in strings.values():\n",
    "    for string in lista:\n",
    "        print(regex.findall(r\"\\d{2}/\\d{2}/\\d{4}\", string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'InformeResultados1-110600.pdf': [{'15-NOV-2019', '06/08/1996'}],\n",
      " 'Wed Nov 13 18:05:58 CST 2019.pdf': [{'06/08/1996', '13-NOV-2019'}],\n",
      " 'gustavo_maganna_2018-01-19.pdf': [{'19-ENE-2018', '06/08/1996'}],\n",
      " 'gustavo_maganna_2018-05-06.pdf': [{'06/08/1996'}],\n",
      " 'gustavo_maganna_2018-05-13.pdf': [{'13/05/2018', '06/08/1996'}],\n",
      " 'gustavo_maganna_2019-11-13.pdf': [{'06/08/1996', '13-NOV-2019'}]}\n"
     ]
    }
   ],
   "source": [
    "dates = {}\n",
    "for nombre, lista in strings.items():\n",
    "    _tmp_list = []\n",
    "    for string in lista:\n",
    "        _tmp_val = set(regex.findall(r\"(\\d{2}\\D[A-Z]{3}\\D\\d{4}|\\d{2}\\D\\d{2}\\D\\d{4})\", string))\n",
    "        if len(_tmp_list) == 0:\n",
    "            _tmp_list.append(_tmp_val)\n",
    "        else:\n",
    "            if _tmp_val not in _tmp_list:\n",
    "                _tmp_list.append(_tmp_val)\n",
    "    dates.update({\n",
    "        nombre: _tmp_list\n",
    "    })\n",
    "pprint.pprint(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'InformeResultados1-110600.pdf': ['15-NOV-2019', '06/08/1996'],\n",
      " 'Wed Nov 13 18:05:58 CST 2019.pdf': ['06/08/1996', '13-NOV-2019'],\n",
      " 'gustavo_maganna_2018-01-19.pdf': ['19-ENE-2018', '06/08/1996'],\n",
      " 'gustavo_maganna_2018-05-06.pdf': ['06/08/1996'],\n",
      " 'gustavo_maganna_2018-05-13.pdf': ['13/05/2018', '06/08/1996'],\n",
      " 'gustavo_maganna_2019-11-13.pdf': ['06/08/1996', '13-NOV-2019']}\n"
     ]
    }
   ],
   "source": [
    "dates = {}\n",
    "for nombre, lista in strings.items():\n",
    "    _tmp_list = []\n",
    "    for string in lista:\n",
    "        _tmp_list += list(set(\n",
    "            regex.findall(r\"(\\d{2}\\D[A-Z]{3}\\D\\d{4}|\\d{2}\\D\\d{2}\\D\\d{4})\", string)\n",
    "        ))\n",
    "    dates.update({\n",
    "        nombre: list(set(_tmp_list))\n",
    "    })\n",
    "\n",
    "for nombre, lista in dates.items():\n",
    "    dates[nombre] = lfilter(lambda x: x if x != someval else False, lista)\n",
    "    \n",
    "\n",
    "pprint.pprint(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARANDA DE LA PARRA DIR. (477) 719-71-02 CONM. 719-71-00 EXT. 143 Y 145 TEL/FAX: 713-33-03\n",
      "\tARANDA DE LA PARRA DIR\n",
      "\t\t477\n",
      "\t\t719\n",
      "\t\t71\n",
      "\t\t02\n",
      "\t\t719\n",
      "\t\t71\n",
      "\t\t00\n",
      "\t\t143\n",
      "\t\t145\n",
      "\t\t713\n",
      "\t\t33\n",
      "\t\t03\n",
      "\t\t\t CONM.\n",
      "\t\t\t EXT.\n",
      "\t\t\t Y\n",
      "\t\t\t TEL/FAX:\n",
      "HEMOGLOBINA........0ccccceeeeeeeeeeeee 16.9 g/dL t 14.10 - 16.30\n",
      "\tHEMOGLOBINA\n",
      "\t\t0\n",
      "\t\t16.9\n",
      "\t\t14.10\n",
      "\t\t16.30\n",
      "\t\t\tccccceeeeeeeeeeeee\n",
      "\t\t\t g/dL\n",
      "\t\t\t -\n",
      "HEMATOCRITO. 48.0 % tT 41-47\n",
      "\tHEMATOCRITO\n",
      "\t\t48.0\n",
      "\t\t41\n",
      "\t\t47\n",
      "\t\t\t %\n",
      "V.C.M.... 86.2 fL 84 - 94\n",
      "\tV\n",
      "\t\t86.2\n",
      "\t\t84\n",
      "\t\t94\n",
      "\t\t\t fL\n",
      "\t\t\t -\n",
      "LEUCOCITOS.......cccccecceecneeeeeeeeee 5.9 Mil/microL 5.30 - 9.50\n",
      "\tLEUCOCITOS\n",
      "\t\t5.9\n",
      "\t\t5.30\n",
      "\t\t9.50\n",
      "\t\t\t Mil/microL\n",
      "\t\t\t -\n",
      "PLAQUETAS.......0ccccccceeee tsetse 163 Mil/microL 150 - 450\n",
      "\tPLAQUETAS\n",
      "\t\t0\n",
      "\t\t163\n",
      "\t\t150\n",
      "\t\t450\n",
      "\t\t\tccccccceeee\n",
      "\t\t\t Mil/microL\n",
      "\t\t\t -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tab_by_regex(strings[archivos[1]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEPURACION DE CREATININA': {'values': [133.6, 75.0, 115.0],\n",
       "  'units': [' mL/min']},\n",
       " 'CREATININA': {'values': [0.92, 0.61, 1.24], 'units': [' mg/dL', ' -']},\n",
       " 'CREATININA URINARIA': {'values': [82.6, 39.0, 259.0],\n",
       "  'units': [' mg/dL', ' -']},\n",
       " 'SUP': {'values': [1.86, 2.0], 'units': []},\n",
       " 'MICROALBUMINURIA': {'values': [10.0, 0.0, 100.0], 'units': [' mg/L']}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = dict_from_regex(strings['gustavo_maganna_2018-01-19.pdf'][0])\n",
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guarda(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13',\n",
       " 'gustavo_maganna_2018-05-06',\n",
       " 'gustavo_maganna_2019-11-13',\n",
       " 'Wed Nov 13 18:05:58 CST 2019',\n",
       " 'InformeResultados1-110600',\n",
       " 'gustavo_maganna_2018-01-19']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gustavo_maganna_2018-05-06.pdf\n",
      "5\n",
      "LABORATORIO DE PATOLOGIA CLINICA\n",
      "\n",
      "HOSPITAL AVENIDA HIDALGO No 329 C.P. : 37000 LEON, GTO.\n",
      "ARANDA DE LA PARRA DIR. (477) 719-71-02 CONM. 719-71-00 EXT. 143 Y 145 TEL/FAX: 713-33-03\n",
      "TODA LA VIDA CONTIGO\n",
      "Paciente: GUSTAVO MAGANA LOPEZ Edad: 21 ANOS Sexo: MASCULINO — Cuarto — Cama:\n",
      "Expediente: Folio: 028028 Seccion: EXTERNO\n",
      "Fecha Nac.:06/08/1996 Fecha ingreso: 6-MAY-2018 09:20 AM_ Fecha—Hora ler Impresion:6-MAY-2018 01:34 PM\n",
      "\n",
      "Médico:JUAN CARLOS FERRER SERRANO Procedencia: H. ARANDA DE LA\n",
      "\n",
      "Ultima Impresion: 6-MAY-2018 07:58 PM\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "PARRA\n",
      ". U. de :\n",
      "Estudio Resultado Medida Intervalo de Referencia\n",
      "PERFIL DE LIPIDOS\n",
      "COLESTEROL....sssssssssssssssesssssssseeeeees 118 mg/dL | 140 - 200 v\n",
      "< 150 Normal\n",
      "TRIGLICERIDOS ....csscsscssessenseesee 50 mg/dL 300-500 Noe v\n",
      ">500 Muy Alto\n",
      "VLDL COLESTEROL.....s-:ssccssssssseeeeeee 10 mg/dL 5-35\n",
      "< 100 Optimo |\n",
      "LDL COLESTEROL...sscssssssssessssesenee 72 mg/dL 130. 169 Lenwnte ato v\n",
      "160 - 189 Alto\n",
      ">= 190 Muy Alto\n",
      "INDICE DE RIESGO CORONARIO\n",
      "HDL COLESTEROL.......csssccsssseeeesseee 33 mg/dL IEERMEDIO. cases v\n",
      "ALTO... MENOR A 35,\n",
      "LIPIDOS TOTALES......:ssssssscsseeesssesseees 337 mg/dL | 450 - 1000\n",
      "INDICE ATEROGENICO... 3.6 RiEScO INTERMEDIO: 4.5 -8\n",
      "\n",
      " \n",
      "\n",
      "METODOLOGIA: ESPECTROFOTOMETRIA AUTOMATIZADA\n",
      "TIPO DE MUESTRA: SUERO\n",
      "\n",
      "NOTA: Este reporte no constituye un diagndstico. Consulte a su médico.\n",
      "\n",
      "Responsable sanitario: Dr. Gilberto Aguilar Orozco, Patélogo Clinico, U.A.N.L.\n",
      "\n",
      "Céd. Prof. 1186314. Registro de especialista SSG 1294 SEP: Autorizacion AE-003261.\n",
      "\n",
      "El laboratorio tiene a su disposiciOn la verificacion de la validacion del método,\n",
      "\n",
      "en caso que desee consultarlo.\n",
      "\n",
      "Aviso: Si requiere que los resultados sean emitidos en Unidades Internacionales,\n",
      "\n",
      "favor de solicitarlo al laboratorio.\n",
      "\n",
      "Laboratorio Clinico acreditado por ema, a.c. con acreditacion No CL-078. Las pruebas en el alcance\n",
      "\n",
      "de la acreditacién estan identificadas con el simbolo V\n",
      "\n",
      "RIESGO BAJO: < 4.5\n",
      "\n",
      "Atentamente\n",
      "\n",
      "Dr. Gilberto Aguilar Orozco.\n",
      "\n",
      "Pagina 3 de 5\n"
     ]
    }
   ],
   "source": [
    "_file = archivos[1]\n",
    "print(_file)\n",
    "print(len(strings[_file]))\n",
    "print(strings[_file][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor line in foo_lines:\\n    for i in regex.finditer(r\"[0a-z]{2,}\", line):\\n        print(foo_lines[14])\\n        #print(i.string)\\n        #print(\\'\\t\\', i.group())\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = strings[_file][2]\n",
    "\n",
    "# Split by line breaks :\n",
    "foo_lines = foo.split(\"\\n\")\n",
    "\n",
    "# Select valid lines (i.e. longer than 5 characters) :\n",
    "foo_lines = [ line for line in foo_lines ] # if len(line) > 1 ]\n",
    "\n",
    "#regex.compile(r'[A-Z]')\n",
    "print(foo_lines[10])\n",
    "print(foo_lines[14])\n",
    "\"\"\"\n",
    "for line in foo_lines:\n",
    "    for i in regex.finditer(r\"[0a-z]{2,}\", line):\n",
    "        print(foo_lines[14])\n",
    "        #print(i.string)\n",
    "        #print('\\t', i.group())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tab_by_regex(strings[archivos[2]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13',\n",
       " 'gustavo_maganna_2018-05-06',\n",
       " 'gustavo_maganna_2019-11-13',\n",
       " 'Wed Nov 13 18:05:58 CST 2019',\n",
       " 'InformeResultados1-110600',\n",
       " 'gustavo_maganna_2018-01-19']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustavo_maganna_2018-05-13.pdf',\n",
       " 'gustavo_maganna_2018-05-06.pdf',\n",
       " 'gustavo_maganna_2019-11-13.pdf',\n",
       " 'Wed Nov 13 18:05:58 CST 2019.pdf',\n",
       " 'InformeResultados1-110600.pdf',\n",
       " 'gustavo_maganna_2018-01-19.pdf']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gml/Documents/IX/imagenes/FinalDeImagenes/segmented'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camino_resultados = os.path.abspath('segmented')\n",
    "camino_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('hue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, archivo in enumerate(archivos):\n",
    "    for j, page in enumerate(strings[archivo]):\n",
    "        with open(os.path.join(camino_resultados, f\"{nombres[i]}.{j+1}.txt\"), 'w') as f:\n",
    "            f.write(tab_by_regex(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline = lambda x: f\"{x}\\n\"\n",
    "ntab = lambda n, txt: n*\"\\t\" + txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for archivo in archivos:\n",
    "    for hoja in strings[archivo]:\n",
    "        print(dict_from_regex(hoja))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_my_str = ''\n",
    "for line in foo_lines:\n",
    "    for i in regex.finditer(r\"^([A-Z\\s]|[A-Z]\\.?)+?(?=(\\..+))\", line): # FIND lines starting with Caps \n",
    "        _my_str += newline(i.string)\n",
    "        _my_str += newline(ntab(1, i.group()))\n",
    "        for j in regex.finditer(r\"(\\d+\\.\\d+|\\d+)\", i.string): # find groups of numbers\n",
    "            _my_str += newline(ntab(2, j.group()))\n",
    "        for k in regex.finditer(r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\d]+?(?=\\s)\", i.string):\n",
    "            _my_str += newline(ntab(3, k.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARANDA DE LA PARRA DIR. (477) 719-71-02 CONM. 719-71-00 EXT. 143 Y 145 TEL/FAX: 713-33-03\n",
      "\tARANDA DE LA PARRA DIR\n",
      "\t\t477\n",
      "\t\t719\n",
      "\t\t71\n",
      "\t\t02\n",
      "\t\t719\n",
      "\t\t71\n",
      "\t\t00\n",
      "\t\t143\n",
      "\t\t145\n",
      "\t\t713\n",
      "\t\t33\n",
      "\t\t03\n",
      "\t\t\t CONM.\n",
      "\t\t\t EXT.\n",
      "\t\t\t Y\n",
      "\t\t\t TEL/FAX:\n",
      "COLESTEROL....sssssssssssssssesssssssseeeeees 118 mg/dL | 140 - 200 v\n",
      "\tCOLESTEROL\n",
      "\t\t118\n",
      "\t\t140\n",
      "\t\t200\n",
      "\t\t\t mg/dL\n",
      "\t\t\t -\n",
      "TRIGLICERIDOS ....csscsscssessenseesee 50 mg/dL 300-500 Noe v\n",
      "\tTRIGLICERIDOS \n",
      "\t\t50\n",
      "\t\t300\n",
      "\t\t500\n",
      "\t\t\t mg/dL\n",
      "\t\t\t Noe\n",
      "VLDL COLESTEROL.....s-:ssccssssssseeeeeee 10 mg/dL 5-35\n",
      "\tVLDL COLESTEROL\n",
      "\t\t10\n",
      "\t\t5\n",
      "\t\t35\n",
      "\t\t\t mg/dL\n",
      "LDL COLESTEROL...sscssssssssessssesenee 72 mg/dL 130. 169 Lenwnte ato v\n",
      "\tLDL COLESTEROL\n",
      "\t\t72\n",
      "\t\t130\n",
      "\t\t169\n",
      "\t\t\t mg/dL\n",
      "\t\t\t Lenwnte\n",
      "HDL COLESTEROL.......csssccsssseeeesseee 33 mg/dL IEERMEDIO. cases v\n",
      "\tHDL COLESTEROL\n",
      "\t\t33\n",
      "\t\t\t mg/dL\n",
      "ALTO... MENOR A 35,\n",
      "\tALTO\n",
      "\t\t35\n",
      "LIPIDOS TOTALES......:ssssssscsseeesssesseees 337 mg/dL | 450 - 1000\n",
      "\tLIPIDOS TOTALES\n",
      "\t\t337\n",
      "\t\t450\n",
      "\t\t1000\n",
      "\t\t\t mg/dL\n",
      "\t\t\t -\n",
      "INDICE ATEROGENICO... 3.6 RiEScO INTERMEDIO: 4.5 -8\n",
      "\tINDICE ATEROGENICO\n",
      "\t\t3.6\n",
      "\t\t4.5\n",
      "\t\t8\n",
      "\t\t\t RiEScO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor line in foo_lines:\\n    for i in regex.finditer(r\"^([A-Z\\\\s]|[A-Z]\\\\.?)+?(?=(\\\\..+))\", line): # FIND lines starting with Caps \\n        print(i.string)\\n        print(\\'\\t\\',i.group())\\n        for j in regex.finditer(r\"(\\\\d+\\\\.\\\\d+|\\\\d+)\", i.string): # find groups of numbers\\n            print(2*\\'\\t\\',j.group())\\n        for k in regex.finditer(r\"(?<=(\\\\d+\\\\.\\\\d+|\\\\d+))\\\\D[^\\\\d]+?(?=\\\\s)\", i.string):\\n            print(3*\\'\\t\\',k.group())\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for line in foo_lines:\n",
    "    for i in regex.finditer(r\"^([A-Z\\s]|[A-Z]\\.?)+?(?=(\\..+))\", line): # FIND lines starting with Caps \n",
    "        print(i.string)\n",
    "        print('\\t',i.group())\n",
    "        for j in regex.finditer(r\"(\\d+\\.\\d+|\\d+)\", i.string): # find groups of numbers\n",
    "            print(2*'\\t',j.group())\n",
    "        for k in regex.finditer(r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\d]+?(?=\\s)\", i.string):\n",
    "            print(3*'\\t',k.group())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My regexps :\n",
    "\n",
    "my_may_ge_2 = r\"^[A-Z]{2,}\"  # Find CAPITAL WORDS longer than 2, at the begining of the line.\n",
    "my_numbers = r\"(\\d+\\.\\d+|\\d+)\" # Find numbers of any length, with a decimal point or not.\n",
    "my_from_begining_until_point = r\"^.+?(?=(\\..+))\" # Find any text before the first occurrence of a pint\n",
    "my_caps_and_whitespace_until_point = r\"^[A-Z\\s]+?(?=(\\..+))\"\n",
    "my_caps_and_whitspace_or_acronym_until_point = r\"^([A-Z\\s|[A-Z]\\.?)+?(?=(\\..+))\"\n",
    "my_failed_extract_units = r\"(?<=((\\d+\\.\\d+|\\d+)+))(.+)\"\n",
    "googled_text_between_brackets = r\"(?<=\\[).+?(?=\\])\"\n",
    "my_extract_units = r\"(?<=(\\d+\\.\\d+|\\d+))\\D+?(?=(\\d+\\.\\d+|\\d+))\"\n",
    "my_better_extract_units_between_numbers = r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\.\\d]+?(?=(\\d+\\.\\d+|\\d+))\"\n",
    "my_extract_units_between_numbers_and_whitespace = r\"(?<=(\\d+\\.\\d+|\\d+))\\D[^\\.\\d]+?(?=\\s)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function purge in module regex.regex:\n",
      "\n",
      "purge()\n",
      "    Clear the regular expression cache\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir(regex)\n",
    "help(regex.purge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABORATORIO\n",
      "HOSPITAL\n",
      "ARANDA\n",
      "TODA\n",
      "PARRA\n",
      "PERFIL\n",
      "COLESTEROL\n",
      "TRIGLICERIDOS\n",
      "VLDL\n",
      "LDL\n",
      "INDICE\n",
      "HDL\n",
      "ALTO\n",
      "LIPIDOS\n",
      "INDICE\n",
      "METODOLOGIA\n",
      "TIPO\n",
      "NOTA\n",
      "RIESGO\n"
     ]
    }
   ],
   "source": [
    "for line in foo_lines:\n",
    "    for i in regex.findall(r\"^[A-Z]{2,}\", line):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"\\n hola \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n hola \\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"{}\".format(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n\\nhola\n"
     ]
    }
   ],
   "source": [
    "print(r'\\n\\nhola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('watever', 'w') as lol:\n",
    "    lol.write(strings[archivos[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'page' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-95d6aff11d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m caracteres_por_linea = pd.core.series.Series(\n\u001b[1;32m      3\u001b[0m     [\n\u001b[0;32m----> 4\u001b[0;31m      \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mpdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'page' is not defined"
     ]
    }
   ],
   "source": [
    "# Cuántas líneas tenemos en total :\n",
    "caracteres_por_linea = pd.core.series.Series(\n",
    "    [\n",
    "     len(line) for line in page.split('\\n') \n",
    "     for pdf in strings \n",
    "     for page in pdf\n",
    "    ],\n",
    "    name='caracteres'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'caracteres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-af66243ab376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaracteres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'caracteres' is not defined"
     ]
    }
   ],
   "source": [
    "sns.distplot(caracteres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
